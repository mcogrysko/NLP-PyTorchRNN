{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49807362",
   "metadata": {},
   "source": [
    "### Mike Ogrysko\n",
    "### CS 766 Information Retrieval and Natural Language Processing\n",
    "\n",
    "Build classifier to distinguish between English and Scottish surnames\n",
    "- Use surnames dataset\n",
    "- PyTorch RNN with 10-fold cross validation performance\n",
    "- Tune by setting WEIGHTS to None\n",
    "- Set performance metric to F1-score and compare results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a316ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os import listdir, path\n",
    "import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1122b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = 'surnames/'\n",
    "\n",
    "# Size of the longest surname, T\n",
    "SEQ_SIZE = 20\n",
    "\n",
    "LANGS = ('English', 'Scottish')\n",
    "\n",
    "LANGS_CAT = dict(zip(LANGS, range(len(LANGS))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94783e",
   "metadata": {},
   "source": [
    "**PyTorch RNN with 10-fold cross validation performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73376fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letter index 0 is the padding value, i.e. padding to fill up the vector to SEQ_SIZE, necessary for batched\n",
    "# Note that eventually we will use torch Tensor to represent these fixed length sequences\n",
    "LetterVocabulary, LetterVocabularyIndex, Index2Voc, Sequences = {' ':0}, 1, {0:' '}, {}\n",
    "for fn in sorted([_ for _ in listdir(PATH_DATA) if _.endswith('.txt')]):\n",
    "    lang, seqs = path.splitext(path.basename(fn))[0], []\n",
    "\n",
    "    if lang not in LANGS:  # test case\n",
    "        continue\n",
    "\n",
    "    with open(path.join(PATH_DATA, fn), 'r', encoding=\"utf8\") as fin:\n",
    "        for row in fin.read().splitlines():\n",
    "            seq = np.zeros(SEQ_SIZE, dtype=np.int32)\n",
    "            for i, letter in enumerate(row.lower()):  # Convert the surname to lower case\n",
    "#            for i, letter in enumerate(row):\n",
    "                if i < SEQ_SIZE:\n",
    "                    if letter not in LetterVocabulary:\n",
    "                        LetterVocabulary[letter] = LetterVocabularyIndex\n",
    "                        Index2Voc[LetterVocabularyIndex] = letter\n",
    "                        LetterVocabularyIndex += 1\n",
    "                    seq[i] = LetterVocabulary[letter]\n",
    "            seqs += [seq]\n",
    "    Sequences[lang] = seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfba051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3768 20 2\n"
     ]
    }
   ],
   "source": [
    "# Sanity\n",
    "N = sum([len(Sequences[_]) for _ in Sequences])\n",
    "\n",
    "T = Sequences['English'][0].shape[0]\n",
    "\n",
    "C = len(np.unique(Sequences.keys())[0])\n",
    "\n",
    "print(N, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3595afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M= 26\n"
     ]
    }
   ],
   "source": [
    "# Pool all sequences and all languages\n",
    "Seqs = [Sequences[LANGS[_]] for _ in range(C)]\n",
    "Seqs = list(itertools.chain(*Seqs))\n",
    "\n",
    "# Number of features is the number of unique characters\n",
    "M = np.max(Seqs)\n",
    "print(f'M= {M}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e42216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0265, 0.9735])\n"
     ]
    }
   ],
   "source": [
    "# Apriori class balance, i.e. inverse probability of the class\n",
    "nk = np.array([len(Sequences[LANGS[_]]) for _ in range(C)], dtype=np.float32)\n",
    "nk = (N/nk)\n",
    "nk = nk/nk.sum()\n",
    "\n",
    "# Class weights, inverse apriori probability\n",
    "WEIGHTS = torch.tensor(nk, dtype=torch.float32)\n",
    "\n",
    "print(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8d1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y = [[_]*len(Sequences[LANGS[_]]) for _ in range(C)]\n",
    "y = np.array(list(itertools.chain(*y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a29bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode every position of the sequence\n",
    "X = np.empty((N,M))\n",
    "n = 0\n",
    "for lang in Sequences.keys():\n",
    "    for seq in Sequences[lang]:\n",
    "        sxx = np.zeros((M,), dtype=np.float32)\n",
    "        for i in range(SEQ_SIZE):  # for the duration of the signal\n",
    "            if seq[i] > 0:\n",
    "                sxx[seq[i]-1] = 1\n",
    "        X[n] = sxx\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711d052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3768\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode every position of the sequence\n",
    "# List of sequence, language tuples for easy shuffling\n",
    "def get_Xy():\n",
    "    Xy = []\n",
    "    for lang in Sequences.keys():\n",
    "        for seq in Sequences[lang]:\n",
    "            T = SEQ_SIZE  # necessary for batched\n",
    "            sxx = np.zeros((T, M))\n",
    "            for i in range(T):  # for the duration of the signal\n",
    "                if seq[i] > 0:\n",
    "                    sxx[i, seq[i]-1] = 1\n",
    "            Xy += [(torch.tensor(sxx, dtype=torch.float32),\n",
    "                    torch.tensor([LANGS_CAT[lang]], dtype=torch.int64))]\n",
    "    return Xy\n",
    "\n",
    "# Helper functions\n",
    "def get_X(_Xy):\n",
    "    return [_[0] for _ in _Xy]\n",
    "    \n",
    "def get_y(_Xy):\n",
    "    return [int(_[1].data[0]) for _ in _Xy]\n",
    "\n",
    "# Sanity\n",
    "Xy = get_Xy()\n",
    "print(len(Xy))\n",
    "\n",
    "# printing the confusion matrix below\n",
    "def get_cm(_y, _p):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import pandas as pd\n",
    "\n",
    "    cm = confusion_matrix(_y, _p, labels=list(range(len(LANGS))))\n",
    "    display(pd.DataFrame(cm, index=[_[:5] for _ in LANGS], columns=[_[:5] for _ in LANGS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2f3f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My_RNN(\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      "  (criterion): NLLLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set the GPU to device 0\n",
    "# gpu = torch.device('cuda:0')\n",
    "#gpu = torch.device('mps') for mac\n",
    "gpu = torch.device('cpu')\n",
    "\n",
    "class My_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden, n_hid_layers=1, epochs=10, eta=0.0005, batch_size=100, weight=None, info=True):\n",
    "        \"\"\" A PyTorch neural network model based on RNN cell, batched \"\"\"\n",
    "        super(My_RNN, self).__init__()\n",
    "\n",
    "        self.n_hidden= n_hidden  # hidden layer size\n",
    "        self.n_hid_layers= n_hid_layers  # number of hidden layers\n",
    "        self.epochs= epochs  # number of learning iterations\n",
    "        self.eta= eta  # learning rate\n",
    "        self.B= batch_size  # size of training batch - 1 would not work\n",
    "        self.info= info  # debug info\n",
    "        \n",
    "        self.rnn, self.outlayer = None, None\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        # loss function, since the last layer is nn.LogSoftmax\n",
    "        self.criterion = nn.NLLLoss(weight=weight)\n",
    "\n",
    "    def forward(self, _X, _h0):\n",
    "        output, hn = self.rnn(_X, _h0)\n",
    "        output = self.outlayer(output[:, -1, :])  # output is batched\n",
    "        output = self.softmax(output)\n",
    "        return output, hn\n",
    "    \n",
    "    def init_cell(self, _M):  # Create variations of our RNN by overriding init_cell\n",
    "        dropout = 0.2 if self.n_hid_layers > 1 else 0\n",
    "        return nn.RNN(_M, self.n_hidden, self.n_hid_layers,\n",
    "                      nonlinearity='relu',\n",
    "                      bias=False, batch_first=True, dropout=dropout)\n",
    "\n",
    "    def init_hidden(self, _B):  # batch_first = True\n",
    "        return torch.zeros(self.n_hid_layers, _B, self.n_hidden).to(gpu)  # Extra dimension - batch\n",
    "\n",
    "    def fit(self, _Xy):\n",
    "        from random import shuffle\n",
    "        import sys\n",
    "        import torch.optim as optim\n",
    "\n",
    "        M= _Xy[0][0].shape[1]  # number of features, based on batch input\n",
    "        C= np.unique([int(_[1].data[0]) for _ in _Xy]).shape[0]  # number of class labels\n",
    "\n",
    "        self.rnn = self.init_cell(M).to(gpu)\n",
    "        self.outlayer = nn.Linear(self.n_hidden, C).to(gpu)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.eta)\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            # Shuffle the input to randomly interleave classes, note that they are tuples, i.e. (x, y)\n",
    "            shuffle(_Xy)\n",
    "\n",
    "            N = len(_Xy)\n",
    "            L, totloss = 0, 0\n",
    "\n",
    "            while L < N-self.B:\n",
    "                sxx = torch.stack([_[0] for _ in _Xy[L:L+self.B]]).to(gpu)\n",
    "                y = torch.tensor([_[1] for _ in _Xy[L:L+self.B]], dtype=torch.int64).to(gpu)\n",
    "                output, loss = self.train_signal(sxx, y, self.B)\n",
    "                \n",
    "                totloss += loss\n",
    "                L += self.B\n",
    "                \n",
    "                if self.info:\n",
    "                    sys.stderr.write(f\"\\r{i+1:03d}/{self.epochs:4d} | Loss: {loss:6.2f} | \"\n",
    "                                     f\"Avg loss: {totloss/(i+1):6.2f} | {y.data.tolist()[0]}\")\n",
    "                    sys.stderr.flush()\n",
    "    \n",
    "    def train_signal(self, _sxx, _y, _B):\n",
    "        h0 = self.init_hidden(_B)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        output, hn = self.forward(_sxx, h0)\n",
    "\n",
    "        loss = self.criterion(output, _y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return output, loss.item()\n",
    "\n",
    "    def predict(self, _sxx):  # Tensor dimensions: B x T x M\n",
    "        _sxx = torch.stack(_sxx)\n",
    "        with torch.no_grad():\n",
    "            h0 = self.init_hidden(_sxx.shape[0])  # reset the hidden layer\n",
    "            output, hn = self.forward(_sxx.to(gpu), h0)\n",
    "\n",
    "        p_values, indices = output.max(dim=1)\n",
    "        return indices.to('cpu')\n",
    "\n",
    "\n",
    "# Info about the RNN\n",
    "print(My_RNN(10, n_hid_layers=1, eta=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f7130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_LSTM(My_RNN):\n",
    "\n",
    "    def __init__(self, n_hidden, n_hid_layers=1, epochs=10, eta=0.0005, batch_size=100, weight=None, info=True):\n",
    "        \"\"\" A PyTorch neural network model based on LSTM RNN cell, batched \"\"\"\n",
    "        super(My_LSTM, self).__init__(n_hidden, n_hid_layers=n_hid_layers,\n",
    "                                      epochs=epochs, eta=eta, batch_size=batch_size, weight=weight, info=info)\n",
    "\n",
    "    def init_hidden(self, _B):  # batch_first = True\n",
    "        return (torch.zeros(self.n_hid_layers, _B, self.n_hidden).to(gpu),\n",
    "                torch.zeros(self.n_hid_layers, _B, self.n_hidden).to(gpu))\n",
    "\n",
    "    def init_cell(self, _M):  # override\n",
    "        dropout = 0.2 if self.n_hid_layers > 1 else 0\n",
    "        return nn.LSTM(_M, self.n_hidden, self.n_hid_layers,\n",
    "                       #nonlinearity='relu',\n",
    "                       bias=False, batch_first=True, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e2a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = get_Xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c85bb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldRnnLSTM(_Xy, _weights):\n",
    "    cm_y, cm_p = [], []\n",
    "    Acc = []\n",
    "    kf = StratifiedKFold(n_splits=10)\n",
    "    for tr_ix, ts_ix in kf.split(np.arange(len(_Xy)), get_y(_Xy)):\n",
    "        rnn = My_LSTM(128, n_hid_layers=1, epochs=1000, eta=0.005, batch_size=2000, weight=_weights, info=True).to(gpu)\n",
    "\n",
    "        X_tr = [_Xy[_] for _ in tr_ix]  # predict uses X and y as a tuple\n",
    "        X_ts = get_X([_Xy[_] for _ in ts_ix])\n",
    "        y_ts = get_y([_Xy[_] for _ in ts_ix])\n",
    "\n",
    "        rnn.fit(X_tr)\n",
    "        y_pred = rnn.predict(X_ts)\n",
    "\n",
    "        Acc += [np.sum(np.array(y_pred) == np.array(y_ts))/len(y_pred)]\n",
    "\n",
    "        cm_y += y_ts\n",
    "        cm_p += y_pred.tolist()\n",
    "\n",
    "    return Acc, cm_y, cm_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4efea200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000/1000 | Loss:   0.20 | Avg loss:   0.00 | 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN 10-fold CV Acc= 0.59 ±0.273\n",
      "CPU times: user 4h 26min 36s, sys: 3h 17min 32s, total: 7h 44min 8s\n",
      "Wall time: 1h 14min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WEIGHTS = torch.tensor(nk, dtype=torch.float32)\n",
    "Acc_we = kfoldRnnLSTM(Xy, WEIGHTS)\n",
    "print(f'RNN 10-fold CV Acc= {np.mean(Acc_we[0]):.2f} {chr(177)}{np.std(Acc_we[0]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c151c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engli</th>\n",
       "      <th>Scott</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Engli</th>\n",
       "      <td>2213</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott</th>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Engli  Scott\n",
       "Engli   2213   1455\n",
       "Scott     73     27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_cm(Acc_we[1], Acc_we[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe801fd",
   "metadata": {},
   "source": [
    "**Tune by setting WEIGHTS to None**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77675814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000/1000 | Loss:   0.12 | Avg loss:   0.00 | 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN 10-fold CV Acc (weights none)= 0.95 ±0.073\n",
      "CPU times: user 4h 35min 46s, sys: 3h 59min 46s, total: 8h 35min 33s\n",
      "Wall time: 2h 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WEIGHTS = None\n",
    "Acc_nwe = kfoldRnnLSTM(Xy, WEIGHTS)\n",
    "print(f'RNN 10-fold CV Acc (weights none)= {np.mean(Acc_nwe[0]):.2f} {chr(177)}{np.std(Acc_nwe[0]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19348f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engli</th>\n",
       "      <th>Scott</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Engli</th>\n",
       "      <td>3576</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Engli  Scott\n",
       "Engli   3576     92\n",
       "Scott    100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_cm(Acc_nwe[1], Acc_nwe[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d025c4",
   "metadata": {},
   "source": [
    "**Set performance metric to F1-score and compare results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e928717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldRnnLSTMF1(_Xy, _weights):\n",
    "    cm_y, cm_p = [], []\n",
    "    Acc = []\n",
    "    kf = StratifiedKFold(n_splits=10)\n",
    "    for tr_ix, ts_ix in kf.split(np.arange(len(_Xy)), get_y(_Xy)):\n",
    "        rnn = My_LSTM(128, n_hid_layers=1, epochs=1000, eta=0.005, batch_size=2000, weight=_weights, info=True).to(gpu)\n",
    "\n",
    "        X_tr = [_Xy[_] for _ in tr_ix]  # predict uses X and y as a tuple\n",
    "        X_ts = get_X([_Xy[_] for _ in ts_ix])\n",
    "        y_ts = get_y([_Xy[_] for _ in ts_ix])\n",
    "\n",
    "        rnn.fit(X_tr)\n",
    "        y_pred = rnn.predict(X_ts)\n",
    "\n",
    "        #Acc += [np.sum(np.array(y_pred) == np.array(y_ts))/len(y_pred)]\n",
    "        Acc += [f1_score(np.array(y_ts),y_pred)]\n",
    "\n",
    "        cm_y += y_ts\n",
    "        cm_p += y_pred.tolist()\n",
    "\n",
    "    return Acc, cm_y, cm_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec1eb811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000/1000 | Loss:   0.50 | Avg loss:   0.00 | 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN F1 Score (Weights) = 0.111 ±0.149\n",
      "CPU times: user 4h 24min 13s, sys: 3h 32min 14s, total: 7h 56min 28s\n",
      "Wall time: 1h 40min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WEIGHTS = torch.tensor(nk, dtype=torch.float32)\n",
    "f1s_we = kfoldRnnLSTMF1(Xy, WEIGHTS)\n",
    "print(f'RNN F1 Score (Weights) = {np.mean(f1s_we[0]):.3f} {chr(177)}{np.std(f1s_we[0]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a18efb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000/1000 | Loss:   0.10 | Avg loss:   0.00 | 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN F1 Score (No Weights) = 0.000 ±0.000\n",
      "CPU times: user 4h 32min 13s, sys: 3h 56min 2s, total: 8h 28min 15s\n",
      "Wall time: 1h 21min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "WEIGHTS = None\n",
    "f1s_nwe = kfoldRnnLSTMF1(Xy, WEIGHTS)\n",
    "print(f'RNN F1 Score (No Weights) = {np.mean(f1s_nwe[0]):.3f} {chr(177)}{np.std(f1s_nwe[0]):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
